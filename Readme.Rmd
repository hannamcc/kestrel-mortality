---
title: "Readme"
author: "Hanna McCaslin"
date: "6/2/2017"
output: html_document
---

This repository contains the code and data for converting individual-by-individual BBL records to MARK frequency data. 

The data from the BBL in May are attached in the 'data' folder in the repository (hopefully). There's also a location file to match up the individual records to a place, just in case. 
```{r, include = FALSE}
source("R/bbl-functions.R")

### Read in encounter data and banding data from BBL (downloaded from ftp May 2017)
encounters <- read_bbl("data/AMKE_encounterdb_201705111648.csv") %>%
     select(BAND_NUM, B_SEX_CODE, B_AGE_CODE, B_FLYWAY_CODE, BANDING_YEAR, E_HOW_OBTAINED_CODE, E_PRESENT_CONDITION_CODE, ENCOUNTER_YEAR, B_REGION, B_LON_DECIMAL_DEGREES)

all_bands <- read_bbl("data/AMKE_bandingdb_201705111647.csv", with_encs = FALSE) %>%
     select(BAND_NUM, B_SEX_CODE = SEX_CODE, B_AGE_CODE = AGE_CODE, B_FLYWAY_CODE = FLYWAY_CODE, BANDING_YEAR, B_REGION = REGION, B_LON_DECIMAL_DEGREES = LON_DECIMAL_DEGREES)
```

## Filtering encounter records
_Update_: Decided this was the more conservative filtering approach, so I used this instead of what Julie describes in email.  
Originally, I just filtered down to only include present condition codes 03, 04, 05 which are the "dead" codes:
```{r}
recoveries <- filter(encounters, E_PRESENT_CONDITION_CODE == 3 | E_PRESENT_CONDITION_CODE == 4 | E_PRESENT_CONDITION_CODE == 5)
# results in encounters n = 3484
```

## Selecting encounter records to remove birds from data entirely
Since some encounter records are ambiguous, we've decided to take these records out of the data entirely. To do this, I created a set of the bad records and tagged them as bad in a new column so I can take them out once I've joined the banding and encounter records.  
To see what the codes look like that I removed, look at filtering-data file.  

```{r}

removals <- encounters %>%
     filter(E_PRESENT_CONDITION_CODE != 3 & E_PRESENT_CONDITION_CODE != 4 & E_PRESENT_CONDITION_CODE != 5) %>% # dead encounters we want, n=3484
     filter(E_PRESENT_CONDITION_CODE != 6 & E_PRESENT_CONDITION_CODE != 7 & E_PRESENT_CONDITION_CODE != 8) %>% # encountered alive and released, n=1508
     filter(!((E_PRESENT_CONDITION_CODE == 0 | E_PRESENT_CONDITION_CODE == 1 | E_PRESENT_CONDITION_CODE == 2) & E_HOW_OBTAINED_CODE == 66)) # unknown present condition but obtained by trapping/banding and releasing, n = 67

#Details about what the unknown/alive & how obtained codes look like is included in filtering-details.txt

## Check and see if birds that have a weird alive encounter record later appear as a dead bird. Take the alive record out of the removals set because we want these to stay in data as dead band recoveries

View(inner_join(recoveries, removals, by = c("BAND_NUM"))%>%
          select(BAND_NUM, ENCOUNTER_YEAR.x, ENCOUNTER_YEAR.y, E_PRESENT_CONDITION_CODE.x, E_PRESENT_CONDITION_CODE.y, E_HOW_OBTAINED_CODE.x, E_HOW_OBTAINED_CODE.y)) # n = 13, might want to look further at the ones where the two encounters don't occur in the same year to determine which year to use (this looks like place BBL needs to continue to clean up, it's weird there are two different records for some of these)

### Remove these records from removals
removals <- anti_join(removals, recoveries, by = c("BAND_NUM"))


# Add a column to make it easy to remove all of these from joined data set 

removals <- mutate(removals, remove = "Yes") # n = 427 to remove from data set
```


## Joining recoveries and removals with banding records 

Joining the recovery records onto the end of the banding records by band number will amend any banding records for recovered birds with the recovery information. This does not change the number of records in the data.  

```{r, include = FALSE}
bands_and_recoveries <- full_join(all_bands, recoveries, by = c("BAND_NUM"))

bands_and_recoveries <- select(bands_and_recoveries, BAND_NUM, SEX = B_SEX_CODE.x, AGE = B_AGE_CODE.x, FLYWAY = B_FLYWAY_CODE.x, BANDING_YEAR = BANDING_YEAR.x, B_REGION = B_REGION.x, B_LON = B_LON_DECIMAL_DEGREES.x, ENCOUNTER_YEAR, E_HOW_OBTAINED = E_HOW_OBTAINED_CODE, E_CONDITION = E_PRESENT_CONDITION_CODE)
```

Joining the removals records onto the end of the banding records will add a column onto the end of the data, and bad records will have a value in a column that is null for good records. This increases the size of the data (barely) because some bands were encountered multiple times. Removing these records will eliminate the duplicates.

```{r}
bands_and_recoveries <- full_join(bands_and_recoveries, removals, by = c("BAND_NUM"))  

bands_and_recoveries <- filter(bands_and_recoveries, is.na(remove)) # Remove the records marked 'remove'

unfiltered_data <- bands_and_recoveries %>%
     select(BAND_NUM, SEX, AGE, FLYWAY, BANDING_YEAR = BANDING_YEAR.x, B_REGION = B_REGION.x, B_LON, ENCOUNTER_YEAR = ENCOUNTER_YEAR.x, E_HOW_OBTAINED, E_CONDITION) 
```

## Filtering data
After joining the two datasets together, any filtering will actually remove that record/band from the data altogether.   
  
This is the filtering that I ended up doing: removing unknown age and sex, removing Caribbean and South American records, removing Mexico, selecting the correct years, and removing the locals that died in the nest.   
_Update_: I updated the year range to include 2016.   
```{r}
filtered_data <- unfiltered_data %>%
     filter(SEX != 0) %>%  # remove unknown sex
     filter(AGE != 0) %>%  # remove unknown age
     filter(FLYWAY != 8 & FLYWAY != 9) %>% # remove Caribbean & South American records 
     filter(FLYWAY!= 7) %>% # optional: remove mexico
     filter(BANDING_YEAR >= 1967 & BANDING_YEAR <= 2016) %>% 
     filter(is.na(ENCOUNTER_YEAR) | (ENCOUNTER_YEAR >= 1967 & ENCOUNTER_YEAR <= 2016)) %>% # filter to dates of study
     filter(is.na(E_HOW_OBTAINED) | !(AGE == 4 & E_HOW_OBTAINED == 30)) #remove locals died in nest, removes n = 14

# n = 272,349
# n = 2538 encounters
```

_Update_: I also changed all of the HY codes to AHY if they were banded between Jan 1 & Apr 14 (n = 96):
```{r}
hatch_years <- left_join(filtered_data, all_bands, by = c("BAND_NUM")) %>%
     select(BAND_NUM, SEX, AGE, BANDING_YEAR.x, BANDING_MONTH, BANDING_DAY) %>%
     filter(AGE == 02)

HY_to_AHY <- filter(hatch_years, BANDING_MONTH < 4 | (BANDING_MONTH == 4 & BANDING_DAY < 15)) # n = 96
```

```{r, include = FALSE}
errant_HY <- as_vector(HY_to_AHY[,"BAND_NUM"])
band_vector <- as_vector(filtered_data[,"BAND_NUM"])
result <- as_vector(filtered_data[,"AGE"])

for(i in 1:nrow(filtered_data)){
     if(band_vector[i] %in% errant_HY){
          result[i] <- 1
     }
}

filtered_data <- mutate(filtered_data, AGE_update = result)
filtered_data <- select(filtered_data, -AGE)
filtered_data <- rename(filtered_data, AGE = AGE_update)

```

### Without HY
Here's the data with out the hatch years. I actually don't think you eliminated all of these in the first go because it makes us about 10K records short of where you were.
```{r}
data_noHY <- filter(filtered_data, AGE != 02) # removes n = 74610
```

```{r, include = FALSE}
### Transform some columns ----
# Sex (into M and F)
data_chr_traits <- translate_sex(filtered_data, "SEX")
data_chr_noHY <- translate_sex(data_noHY, "SEX")

# Age (into HY and AHY categories)
data_chr_traits <- translate_age(data_chr_traits, "AGE", group = TRUE) 
data_chr_noHY <- translate_age(data_chr_noHY, "AGE", group = TRUE)

#Flyway (into 4)
data_chr_traits <- calc_flyways_four(data_chr_traits, "FLYWAY", "B_LON", chr_codes = FALSE, int_codes = TRUE) 
data_chr_noHY <- calc_flyways_four(data_chr_noHY, "FLYWAY", "B_LON", chr_codes = FALSE, int_codes = TRUE)

#Get rid of some unneccessary columns
amke_individuals <- select(data_chr_traits, BAND_NUM, sex, age_class = b_age, flyway = FLYWAY, b_year = BANDING_YEAR, e_year = ENCOUNTER_YEAR)
amke_indivs_noHY <- select(data_chr_noHY, BAND_NUM, sex, age_class = b_age, flyway = FLYWAY, b_year = BANDING_YEAR, e_year = ENCOUNTER_YEAR)
```


## Final data sets

```{r}
make_ldld <- function(df, study_first_yr, study_last_yr){
     
     reference_year1 <- study_first_yr
     reference_year2 <-study_last_yr
     
     study_length <- (reference_year2 - reference_year1) + 1
     
     #Create a string of 0's of length 2 * study length
     ch <- ""
     m = 0
     while(m < 2 * study_length){
          ch <- str_c(ch, "0")
          m <- m + 1
     }

     band_position <- vector(mode = "integer", length = nrow(df))
     enc_position <- vector(mode = "integer", length = nrow(df))
     result <- vector(mode = "character", length = nrow(df))
     
     for(i in 1:nrow(df)){result[i] = ch} #fill result with character strings
     for(i in 1:nrow(df)){
          band_position[i] <- 2*(df$b_year[i] - (reference_year1-1))-1 # create a vector of all the places the band "1" will go
     }
     for(i in 1:nrow(df)){
          str_sub(result[i], start = band_position[i], end = band_position[i]) <- "1" # update the strings in result with band "1"
     }
     for(i in 1:nrow(df)){
          if(!is.na(df$e_year[i])){
               enc_position[i] <- 2*(df$e_year[i] - (reference_year1-1)) # create a vector of all the places the enc "1" will go
          } else{
               enc_position[i] <- NA
          }
     }
     for(i in 1:nrow(df)){
          if(!is.na(enc_position[i])){
               str_sub(result[i], start = enc_position[i], end = enc_position[i]) <- "1"
          }
     }
     
     result <- str_c("\"", result, "\"") #add " to the ends of the string so excel doesn't eat the 0s
     df$ch <- result
     return(df)
}
```

I made versions including and excluding HYs
```{r}
### Make mark string in dataset
amke_mark <- make_ldld(amke_individuals, 1967, 2016)
amke_noHY_mark <- make_ldld(amke_indivs_noHY, 1967, 2016)

### Group into rows w/ frequencies
grouped_amke <- group_by(amke_mark, ch, sex, age_class, flyway)
final <- summarise(grouped_amke, freq = n())

#And again for no-HYs
grouped_amke_noHY <- group_by(amke_noHY_mark, ch, sex, age_class, flyway)
final_noHY <- summarise(grouped_amke_noHY, freq = n())

```

What's interesting here that I can't totally figure out is that I have about 300 more possible LD/age/sex combinations (rows) than Ben had when he did it, even when I take out the hatch years and have a smaller dataset. Ideas?

## Files
The csvs of the end data with and without hatch years are (hopefully) in the mark-data file in the repository. I'll try to be sure to update them if I change anything.  

As of 6 June 2017, the data files are:  
     "mark-data/LD_amke_6june2017.csv" for with HY   
     "mark-data/LD_amke_noHY_6june2017.csv" for without HY
